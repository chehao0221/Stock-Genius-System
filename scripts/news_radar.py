import yfinance as yf
import requests
import datetime
import os
import feedparser
import urllib.parse
import sys

# =============================
# å°ˆæ¡ˆè·¯å¾‘èˆ‡åŸºç¤è¨­å®š
# =============================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, \"data\")
os.makedirs(DATA_DIR, exist_ok=True)

DISCORD_WEBHOOK_URL = os.getenv(\"NEWS_WEBHOOK_URL\", \"\").strip()
CACHE_FILE = os.path.join(DATA_DIR, \"news_cache.txt\")
TZ_TW = datetime.timezone(datetime.timedelta(hours=8))
MAX_EMBEDS = 8
NEWS_HOURS_LIMIT = 6  # ç¸®çŸ­æ™‚é–“é™åˆ¶ï¼Œç¢ºä¿æ¶ˆæ¯å¤ å³æ™‚

PRICE_CACHE = {}

# =============================
# è‚¡åƒ¹å¿«å–ç³»çµ± ( yfinance å„ªåŒ–ç‰ˆ )
# =============================
def get_stock_price(sym):
    if sym in PRICE_CACHE: return PRICE_CACHE[sym]
    try:
        t = yf.Ticker(sym)
        info = t.fast_info
        price = info.get(\"last_price\") or t.info.get(\"regularMarketPrice\")
        prev = info.get(\"previous_close\") or t.info.get(\"regularMarketPreviousClose\")
        if price and prev:
            pct = ((price - prev) / prev) * 100
            PRICE_CACHE[sym] = (price, pct)
            return price, pct
    except: pass
    PRICE_CACHE[sym] = (None, None)
    return None, None

# =============================
# é‡é»æ¨™çš„å°ç…§è¡¨ (èå…¥ AI ç³»çµ±æ ¸å¿ƒæ¨™çš„)
# =============================
STOCK_MAP = {
    \"å°ç©é›»\": {\"sym\": \"2330.TW\", \"desc\": \"AIæ™¶ç‰‡ / å…ˆé€²è£½ç¨‹\"},
    \"2330\": {\"sym\": \"2330.TW\", \"desc\": \"AIæ™¶ç‰‡ / å…ˆé€²è£½ç¨‹\"},
    \"é´»æµ·\": {\"sym\": \"2317.TW\", \"desc\": \"AIä¼ºæœå™¨ / çµ„è£\"},
    \"2317\": {\"sym\": \"2317.TW\", \"desc\": \"AIä¼ºæœå™¨ / çµ„è£\"},
    \"è¼é”\": {\"sym\": \"NVDA\", \"desc\": \"NVIDIA / AIé¾é ­\"},
    \"NVIDIA\": {\"sym\": \"NVDA\", \"desc\": \"NVIDIA / AIé¾é ­\"},
    \"ç‰¹æ–¯æ‹‰\": {\"sym\": \"TSLA\", \"desc\": \"Tesla / é›»å‹•è»Š\"},
    \"TSLA\": {\"sym\": \"TSLA\", \"desc\": \"Tesla / é›»å‹•è»Š\"},
    \"è˜‹æœ\": {\"sym\": \"AAPL\", \"desc\": \"Apple / æ‰‹æ©Ÿç«¯AI\"},
    \"AAPL\": {\"sym\": \"AAPL\", \"desc\": \"Apple / æ‰‹æ©Ÿç«¯AI\"},
}

STOCK_WEIGHT = {\"2330.TW\": 5, \"NVDA\": 5, \"2317.TW\": 4, \"TSLA\": 4}

# =============================
# æ ¸å¿ƒé‚è¼¯ï¼šé‡è¦åº¦åˆ¤å®š
# =============================
def pick_most_important_stock(title):
    hits = []
    title_lower = title.lower()
    seen_sym = set()
    for key, info in STOCK_MAP.items():
        pos = title_lower.find(key.lower())
        if pos >= 0:
            sym = info[\"sym\"]
            if sym in seen_sym: continue
            seen_sym.add(sym)
            weight = STOCK_WEIGHT.get(sym, 1)
            score = weight * 100 - pos
            hits.append((score, info))
    if not hits: return None
    hits.sort(reverse=True, key=lambda x: x[0])
    return hits[0][1]

def create_news_embed(post, market_type):
    color = 0x3498db if market_type == \"TW\" else 0xe74c3c
    target = pick_most_important_stock(post[\"title\"])

    if target:
        price, pct = get_stock_price(target[\"sym\"])
        if price:
            trend = \"ğŸ“ˆ åˆ©å¤š\" if pct > 0 else \"ğŸ“‰ åˆ©ç©º\" if pct < 0 else \"â– ä¸­æ€§\"
            return {
                \"title\": f\"ğŸ“Š {target['sym']} | {target['desc']}\",
                \"url\": post[\"link\"],
                \"color\": color,
                \"fields\": [
                    {\"name\": \"âš–ï¸ å¸‚å ´åˆ¤æ–·\", \"value\": trend, \"inline\": True},
                    {\"name\": \"ğŸ’µ å³æ™‚åƒ¹æ ¼\", \"value\": f\"**{price:.2f} ({pct:+.2f}%)**\", \"inline\": True},
                    {\"name\": \"ğŸ“° ç„¦é»æ–°è\", \"value\": f\"[{post['title']}]({post['link']})\\nğŸ•’ {post['time']}\", \"inline\": False},
                ],
                \"footer\": {\"text\": \"Quant Master AI-Radar\"}
            }
    
    return {
        \"title\": post[\"title\"],
        \"url\": post[\"link\"],
        \"color\": color,
        \"fields\": [
            {\"name\": \"ğŸ•’ ç™¼å¸ƒæ™‚é–“\", \"value\": f\"{post['time']} (å°åŒ—)\", \"inline\": True},
            {\"name\": \"ğŸ“° æ–°èä¾†æº\", \"value\": post[\"source\"], \"inline\": True},
        ],
        \"footer\": {\"text\": \"Quant Master AI-Radar\"}
    }

# =============================
# ä¸»åŸ·è¡Œé‚è¼¯
# =============================
def run_radar():
    if not DISCORD_WEBHOOK_URL: return
    
    sent_titles = set()
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, \"r\", encoding=\"utf-8\") as f:
            sent_titles = {l.strip() for l in f if l.strip()}

    now_tw = datetime.datetime.now(TZ_TW)
    market = \"TW\" if 8 <= now_tw.hour < 17 else \"US\"
    queries = [\"å°è‚¡ è²¡ç¶“\", \"å°ç©é›» é´»æµ·\"] if market == \"TW\" else [\"ç¾è‚¡ ç›¤å‰\", \"è¼é” ç‰¹æ–¯æ‹‰\"]
    
    collected = {}
    now_utc = datetime.datetime.now(datetime.timezone.utc)

    for q in queries:
        url = f\"https://news.google.com/rss/search?q={urllib.parse.quote(q)}&hl=zh-TW&gl=TW&ceid=TW:zh-TW\"
        feed = feedparser.parse(url)
        for e in feed.entries[:10]:
            title = e.title.split(\" - \")[0]
            if title in sent_titles or title in collected: continue
            if not hasattr(e, \"published_parsed\"): continue
            pub_utc = datetime.datetime(*e.published_parsed[:6], tzinfo=datetime.timezone.utc)
            if (now_utc - pub_utc).total_seconds() / 3600 > NEWS_HOURS_LIMIT: continue
            
            collected[title] = {
                \"title\": title, \"link\": e.link, \"source\": e.title.split(\" - \")[-1],
                \"time\": pub_utc.astimezone(TZ_TW).strftime(\"%H:%M\"), \"sort\": pub_utc
            }

    posts = sorted(collected.values(), key=lambda x: x[\"sort\"], reverse=True)[:MAX_EMBEDS]
    if not posts: return

    embeds = [create_news_embed(p, market) for p in posts]
    
    # åˆ†æ‰¹æ¨æ’­ (Discord é™åˆ¶ä¸€å‰‡è¨Šæ¯æœ€å¤š 10 å€‹ embeds)
    requests.post(DISCORD_WEBHOOK_URL, json={
        \"content\": f\"### ğŸ“¡ AI é‡‘èé›·é” ({'å°è‚¡' if market=='TW' else 'ç¾è‚¡'}æ™‚æ®µ)\\nğŸ“… `{now_tw.strftime('%Y-%m-%d %H:%M')}`\"
    })
    
    for i in range(0, len(embeds), 4):
        requests.post(DISCORD_WEBHOOK_URL, json={\"embeds\": embeds[i:i+4]})

    # æ›´æ–°ç´€éŒ„
    sent_titles.update(p[\"title\"] for p in posts)
    with open(CACHE_FILE, \"w\", encoding=\"utf-8\") as f:
        for t in list(sent_titles)[-200:]: f.write(f\"{t}\\n\")

if __name__ == \"__main__\":
    run_radar()
