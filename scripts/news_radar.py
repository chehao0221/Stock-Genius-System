import os, sys, json, warnings, datetime, requests, feedparser, urllib.parse
import pandas as pd

# ===============================
# Base / Data
# ===============================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
DATA_DIR = os.path.join(BASE_DIR, "data")
os.makedirs(DATA_DIR, exist_ok=True)
sys.path.append(BASE_DIR)

# ===============================
# Webhook / Flags
# ===============================
NEWS_WEBHOOK_URL = os.getenv("NEWS_WEBHOOK_URL", "").strip()
BLACK_SWAN_WEBHOOK_URL = os.getenv("BLACK_SWAN_WEBHOOK_URL", "").strip()

L4_ACTIVE_FILE = os.path.join(DATA_DIR, "l4_active.flag")
L3_WARNING_FILE = os.path.join(DATA_DIR, "l3_warning.flag")
OBS_FLAG_FILE = os.path.join(DATA_DIR, "l4_last_end.flag")

CACHE_FILE = os.path.join(DATA_DIR, "news_cache.json")

TZ = datetime.timezone(datetime.timedelta(hours=8))
warnings.filterwarnings("ignore")

# ===============================
# Config
# ===============================
L4_TIME_WINDOW_HOURS = 6
L4_TRIGGER_COUNT = 2
L4_NEWS_PAUSE_HOURS = 24
L3_COOLDOWN_HOURS = 6

DISCLAIMER = "ğŸ“Œ æé†’ï¼šåƒ…ç‚ºé¢¨éšªèˆ‡å¸‚å ´ç›£æ§ï¼ŒéæŠ•è³‡å»ºè­°"

# ===============================
# Black Swan Levels
# ===============================
BLACK_SWAN_LEVELS = {
    3: ["ç ´ç”¢", "ä¸‹å¸‚", "bankruptcy", "delist", "halt"],
    2: ["åˆ¶è£", "é•ç´„", "lawsuit", "sec", "sanction"],
    1: ["è£å“¡", "åœç”¢", "èª¿æŸ¥"],
}

def get_black_swan_level(title: str) -> int:
    t = title.lower()
    for level, keys in BLACK_SWAN_LEVELS.items():
        if any(k.lower() in t for k in keys):
            return level
    return 0

# ===============================
# Cache
# ===============================
def load_cache():
    if os.path.exists(CACHE_FILE):
        try:
            return json.load(open(CACHE_FILE, "r", encoding="utf-8"))
        except:
            return {}
    return {}

def save_cache(c):
    json.dump(c, open(CACHE_FILE, "w", encoding="utf-8"),
              ensure_ascii=False, indent=2)

# ===============================
# News Fetch
# ===============================
def get_news(q):
    try:
        url = (
            "https://news.google.com/rss/search?"
            f"q={urllib.parse.quote(q)}&hl=zh-TW&gl=TW&ceid=TW:zh-TW"
        )
        feed = feedparser.parse(url)
        if not feed.entries:
            return None

        e = feed.entries[0]
        return {
            "title": e.title.split(" - ")[0],
            "link": e.link,
            "time": datetime.datetime(
                *e.published_parsed[:6],
                tzinfo=datetime.timezone.utc
            ).astimezone(TZ).strftime("%H:%M")
        }
    except:
        return None

# ===============================
# Main
# ===============================
def run():
    now = datetime.datetime.now(TZ)
    ts = now.timestamp()

    cache = load_cache()
    cache.setdefault("_l3_events", [])
    cache.setdefault("_l4_pause_until", 0)

    # ===============================
    # ğŸ” L4 Auto Recover
    # ===============================
    if os.path.exists(L4_ACTIVE_FILE) and ts > cache["_l4_pause_until"]:
        os.remove(L4_ACTIVE_FILE)
        open(OBS_FLAG_FILE, "w").write(str(ts))

        if BLACK_SWAN_WEBHOOK_URL:
            requests.post(
                BLACK_SWAN_WEBHOOK_URL,
                json={
                    "content": (
                        "ğŸ“Š **L4 é»‘å¤©éµäº‹ä»¶çµæŸ**\n"
                        f"ğŸ•’ {now:%Y-%m-%d %H:%M}\n"
                        "ğŸŸ  ç³»çµ±å·²é€²å…¥é¢¨éšªè§€å¯ŸæœŸ\n\n"
                        f"{DISCLAIMER}"
                    )
                },
                timeout=15,
            )

    # ===============================
    # ä»Šæ—¥ AI ç›£æ§æ¨™çš„
    # ===============================
    symbols = []
    for f in ["tw_history.csv", "us_history.csv"]:
        p = os.path.join(DATA_DIR, f)
        if os.path.exists(p):
            df = pd.read_csv(p)
            latest = df["date"].max()
            symbols += df[df["date"] == latest]["symbol"].tolist()

    black_embeds = []

    for s in set(symbols):
        news = get_news(s.split(".")[0])
        if not news:
            continue

        level = get_black_swan_level(news["title"])
        final_level = level

        # ===== L3 è¨˜éŒ„ =====
        if level == 3:
            cache["_l3_events"].append(ts)
            cache["_l3_events"] = [
                t for t in cache["_l3_events"]
                if ts - t <= L4_TIME_WINDOW_HOURS * 3600
            ]

            # ===== å‡ç´š L4 =====
            if len(cache["_l3_events"]) >= L4_TRIGGER_COUNT:
                final_level = 4
                cache["_l4_pause_until"] = ts + L4_NEWS_PAUSE_HOURS * 3600
                open(L4_ACTIVE_FILE, "w").write(str(ts))
                if os.path.exists(L3_WARNING_FILE):
                    os.remove(L3_WARNING_FILE)

        # ===== L3 Warningï¼ˆåªç™¼ä¸€æ¬¡ï¼‰=====
        if level == 3 and not os.path.exists(L4_ACTIVE_FILE):
            if not os.path.exists(L3_WARNING_FILE):
                open(L3_WARNING_FILE, "w").write(str(ts))
                if BLACK_SWAN_WEBHOOK_URL:
                    requests.post(
                        BLACK_SWAN_WEBHOOK_URL,
                        json={
                            "content": (
                                "ğŸŸ¡ **SYSTEM MODEï¼šé¢¨éšªè­¦ç¤ºï¼ˆL3ï¼‰**\n"
                                f"ğŸ•’ {now:%Y-%m-%d %H:%M}\n"
                                "âš ï¸ åµæ¸¬åˆ°é«˜é¢¨éšªäº‹ä»¶ï¼Œç³»çµ±å°‡é™ä½é€²æ”»è¡Œç‚º\n\n"
                                f"{DISCLAIMER}"
                            )
                        },
                        timeout=15,
                    )

        # ===== Embed =====
        if final_level >= 3:
            black_embeds.append({
                "title": f"{s} | é»‘å¤©éµ L{final_level}",
                "url": news["link"],
                "color": 0x8E0000,
                "fields": [{
                    "name": f"ğŸš¨ é»‘å¤©éµ L{final_level}",
                    "value": f"[{news['title']}]({news['link']})\nğŸ•’ {news['time']}",
                    "inline": False
                }]
            })

    # ===== L3 å†·å»è§£é™¤ =====
    if os.path.exists(L3_WARNING_FILE):
        recent = [t for t in cache["_l3_events"]
                  if ts - t <= L3_COOLDOWN_HOURS * 3600]
        if not recent:
            os.remove(L3_WARNING_FILE)

    # ===== Send =====
    if black_embeds and BLACK_SWAN_WEBHOOK_URL:
        requests.post(
            BLACK_SWAN_WEBHOOK_URL,
            json={
                "content": f"ğŸš¨ **é»‘å¤©éµè­¦å ±**\n\n{DISCLAIMER}",
                "embeds": black_embeds[:10]
            },
            timeout=15,
        )

    save_cache(cache)

if __name__ == "__main__":
    run()
