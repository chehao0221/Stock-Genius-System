import yfinance as yf
import pandas as pd
import numpy as np
import requests
import os
import warnings
from xgboost import XGBRegressor
from datetime import datetime, timedelta

# =========================
# åŸºæœ¬è¨­å®šèˆ‡ç’°å¢ƒåˆå§‹åŒ–
# =========================
warnings.filterwarnings("ignore")
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
HISTORY_FILE = os.path.join(BASE_DIR, "us_history.csv")
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()

def get_us_300_pool():
    """å¾ç¶­åŸºç™¾ç§‘ç²å– S&P 500 å‰ 300 æª”æ¨™çš„ï¼Œè‹¥å¤±æ•—å‰‡å›å‚³é è¨­æ¸…å–®"""
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        headers = {'User-Agent': 'Mozilla/5.0'}
        res = requests.get(url, headers=headers, timeout=10)
        df = pd.read_html(res.text)[0]
        return [s.replace('.', '-') for s in df['Symbol'].tolist()[:300]]
    except Exception:
        return ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META"]

def safe_post(msg: str):
    """ç™¼é€ Discord é€šçŸ¥ï¼Œè‹¥ç„¡ Webhook å‰‡åƒ…åœ¨çµ‚ç«¯æ©Ÿåˆ—å°"""
    if not WEBHOOK_URL:
        print("\n--- Discord è¨Šæ¯é è¦½ ---\n", msg)
        return
    try:
        requests.post(WEBHOOK_URL, json={"content": msg}, timeout=15)
    except Exception as e:
        print(f"ç™¼é€å¤±æ•—: {e}")

def compute_features(df):
    """è¨ˆç®—æŠ€è¡“æŒ‡æ¨™ç‰¹å¾µ"""
    df = df.copy()
    # å‹•èƒ½æŒ‡æ¨™
    df["r"] = df["Close"].pct_change()
    df["mom20"] = df["Close"].pct_change(20)
    
    # RSI æŒ‡æ¨™
    delta = df["Close"].diff()
    gain = delta.clip(lower=0).rolling(14).mean()
    loss = (-delta.clip(upper=0)).rolling(14).mean()
    df["rsi"] = 100 - (100 / (1 + gain / (loss + 1e-9)))
    
    # ä¹–é›¢ç‡èˆ‡é‡èƒ½æ¯”
    df["ma20"] = df["Close"].rolling(20).mean()
    df["bias"] = (df["Close"] - df["ma20"]) / (df["ma20"] + 1e-9)
    df["vol_ratio"] = df["Volume"] / (df["Volume"].rolling(20).mean() + 1e-9)
    
    # æ”¯æ’èˆ‡å£“åŠ›
    df["sup"] = df["Low"].rolling(60).min()
    df["res"] = df["High"].rolling(60).max()
    return df

def audit_and_save(results, top_keys):
    """å°å¸³ 5 æ—¥å‰çš„é æ¸¬çµæœï¼Œä¸¦è¨˜éŒ„ä»Šæ—¥é æ¸¬"""
    if os.path.exists(HISTORY_FILE):
        hist = pd.read_csv(HISTORY_FILE)
        hist["date"] = pd.to_datetime(hist["date"]).dt.date
    else:
        hist = pd.DataFrame(columns=["date", "symbol", "pred_p", "pred_ret", "settled"])
    
    audit_msg = ""
    today = datetime.now().date()
    deadline = today - timedelta(days=8) # è€ƒæ…®å‡æ—¥ï¼Œæª¢æŸ¥ç´„ 5-8 å¤©å‰çš„é æ¸¬
    unsettled = hist[(hist["settled"] == False) & (hist["date"] <= deadline)]
    
    if not unsettled.empty:
        audit_msg = "\nğŸ¯ **5 æ—¥é æ¸¬çµç®—å°å¸³ (US)**\n"
        for idx, r in unsettled.iterrows():
            try:
                p_df = yf.Ticker(r["symbol"]).history(period="5d")
                if p_df.empty: continue
                curr_p = p_df["Close"].iloc[-1]
                act_ret = (curr_p - r["pred_p"]) / r["pred_p"]
                hit = "âœ…" if np.sign(act_ret) == np.sign(r["pred_ret"]) else "âŒ"
                audit_msg += f"`{r['symbol']}` {r['pred_ret']:+.2%} âœ {act_ret:+.2%} {hit}\n"
                hist.at[idx, "settled"] = True
            except: continue
            
    # æ–°å¢ä»Šæ—¥é æ¸¬æ¨™çš„
    new_rows = [{"date": today, "symbol": s, "pred_p": results[s]["c"], "pred_ret": results[s]["p"], "settled": False} for s in top_keys]
    hist = pd.concat([hist, pd.DataFrame(new_rows)], ignore_index=True).drop_duplicates(subset=["date", "symbol"], keep="last")
    hist.to_csv(HISTORY_FILE, index=False)
    return audit_msg

def run():
    must_watch = ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META"]
    pool = get_us_300_pool()
    watch = list(set(must_watch + pool))
    feats = ["mom20", "rsi", "bias", "vol_ratio"]
    results = {}

    print(f"ğŸ“… åŸ·è¡Œæ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M')}")
    print(f"ğŸ” æ­£åœ¨æƒæ {len(watch)} æª”ç¾è‚¡æ¨™çš„...")
    
    # æ‰¹é‡ä¸‹è¼‰æ•¸æ“š
    all_data = yf.download(watch, period="5y", progress=False, group_by="ticker", auto_adjust=True)

    for s in watch:
        try:
            df = all_data[s].dropna()
            if len(df) < 120: continue
            
            df = compute_features(df)
            # ç›®æ¨™ï¼šé æ¸¬ 5 æ—¥å¾Œçš„å ±é…¬ç‡
            df["target"] = df["Close"].shift(-5) / df["Close"] - 1
            
            train = df.dropna()
            if train.empty: continue
            
            model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.05, random_state=42)
            model.fit(train[feats], train["target"])
            
            # é€²è¡Œé æ¸¬ (æœ€æ–°ä¸€ç­†æ•¸æ“š)
            pred = float(np.clip(model.predict(df[feats].iloc[-1:])[0], -0.15, 0.15))
            last_close = float(df["Close"].iloc[-1])
            
            results[s] = {"p": pred, "c": last_close}
        except:
            continue

    # æ’åºä¸¦æŒ‘é¸å‰ 5 æª”
    top_keys = sorted(results, key=lambda x: results[x]["p"], reverse=True)[:5]
    
    # ç”¢å‡ºå ±å‘Š
    report = f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡ AI é¸è‚¡é æ¸¬ (5æ—¥çœ‹æ¼²)**\n"
    for s in top_keys:
        report += f"ğŸ“ˆ `{s}` | é ä¼°å ±é…¬: {results[s]['p']:+.2%} | ç¾åƒ¹: ${results[s]['c']:.2f}\n"
    
    # å°å¸³
    audit_msg = audit_and_save(results, top_keys)
    
    # ç™¼é€
    safe_post(report + audit_msg)

if __name__ == "__main__":
    run()
