import yfinance as yf
import pandas as pd
import numpy as np
import requests
import os
from xgboost import XGBRegressor
from datetime import datetime, timedelta
import warnings

warnings.filterwarnings("ignore")
WEBHOOK_URL = os.getenv("DISCORD_WEBHOOK_URL", "").strip()

# --- æ ¸å¿ƒè·¯å¾‘è¨­å®š ---
HISTORY_FILE = "data/us_history.csv"

def get_us_300_pool():
    try:
        url = "https://en.wikipedia.org/wiki/List_of_S%26P_500_companies"
        df = pd.read_html(requests.get(url).text)[0]
        # è™•ç†ä»£è™Ÿä¸­çš„é»ï¼ˆå¦‚ BRK.B è½‰ç‚º BRK-B ä»¥ç¬¦åˆ yfinance æ ¼å¼ï¼‰
        return [s.replace('.', '-') for s in df['Symbol'].tolist()[:300]]
    except: 
        return ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "META"]

def compute_features(df):
    df = df.copy()
    df["mom20"] = df["Close"].pct_change(20)
    df["rsi"] = 100 - (100 / (1 + df["Close"].diff().clip(lower=0).rolling(14).mean() / ((-df["Close"].diff().clip(upper=0)).rolling(14).mean() + 1e-9)))
    df["ma20"] = df["Close"].rolling(20).mean()
    df["bias"] = (df["Close"] - df["ma20"]) / (df["ma20"] + 1e-9)
    df["vol_ratio"] = df["Volume"] / (df["Volume"].rolling(20).mean() + 1e-9)
    df["sup"] = df["Low"].rolling(60).min()
    df["res"] = df["High"].rolling(60).max()
    return df

def audit_and_save(current_results, top_5_keys):
    audit_msg = ""
    # çµ±ä¸€ä½¿ç”¨å°å¯«æ¬„ä½åä»¥ç¬¦åˆè¦ç¯„
    columns = ['date', 'symbol', 'pred_p', 'pred_ret', 'settled']
    
    if os.path.exists(HISTORY_FILE):
        try:
            hist_df = pd.read_csv(HISTORY_FILE)
            # é—œéµä¿®æ­£ï¼šè§£æ±ºæ—¥æœŸæ ¼å¼æ··åˆå°è‡´çš„ ValueError
            hist_df['date'] = pd.to_datetime(hist_df['date'], format='mixed')
            
            # ç¢ºä¿ settled æ¬„ä½å­˜åœ¨
            if 'settled' not in hist_df.columns: hist_df['settled'] = False
            
            deadline = datetime.now() - timedelta(days=7)
            to_settle = hist_df[(hist_df['date'] <= deadline) & (hist_df['settled'] == False)]
            
            if not to_settle.empty:
                audit_msg = "\nğŸ¯ **5æ—¥é ä¼°çµç®—å°å¸³å–®**\n"
                for idx, row in to_settle.iterrows():
                    try:
                        ticker = yf.Ticker(row['symbol'])
                        curr_data = ticker.history(period="1d")
                        if curr_data.empty: continue
                        
                        curr_p = curr_data['Close'].iloc[-1]
                        actual_ret = (curr_p - row['pred_p']) / row['pred_p']
                        is_hit = "âœ… å‘½ä¸­" if (actual_ret > 0 and row['pred_ret'] > 0) or (actual_ret < 0 and row['pred_ret'] < 0) else "âŒ éŒ¯èª¤"
                        audit_msg += f"`{row['symbol']}`: é ä¼° `{row['pred_ret']:+.2%}` â” å¯¦éš› `{actual_ret:+.2%}` ({is_hit})\n"
                        hist_df.at[idx, 'settled'] = True
                    except: continue
            hist_df.to_csv(HISTORY_FILE, index=False)
        except:
            hist_df = pd.DataFrame(columns=columns)
    else:
        hist_df = pd.DataFrame(columns=columns)

    # ç´€éŒ„ç•¶å‰æ¨è–¦
    new_recs = []
    today_str = datetime.now().strftime("%Y-%m-%d")
    for s in top_5_keys:
        new_recs.append({
            'date': today_str,
            'symbol': s,
            'pred_p': current_results[s]['c'],
            'pred_ret': current_results[s]['p'],
            'settled': False
        })
    
    hist_df = pd.concat([hist_df, pd.DataFrame(new_recs)], ignore_index=True)
    hist_df.to_csv(HISTORY_FILE, index=False)
    return audit_msg

def run():
    if not WEBHOOK_URL: return
    symbols = get_us_300_pool()
    must_watch = ["AAPL", "NVDA", "TSLA", "MSFT", "GOOGL", "AMZN", "QQQ", "SPY", "SOXL"]
    all_syms = list(set(symbols + must_watch))
    
    # yfinance ä¸‹è¼‰
    data = yf.download(all_syms, period="5y", progress=False)
    results = {}
    feats = ["mom20", "rsi", "bias", "vol_ratio"]
    
    for s in all_syms:
        try:
            df = data.xs(s, axis=1, level=1).dropna()
            if len(df) < 60: continue # è³‡æ–™é‡ä¸è¶³è·³é
            
            df = compute_features(df)
            df["target"] = df["Close"].shift(-5) / df["Close"] - 1
            train = df.dropna()
            
            model = XGBRegressor(n_estimators=100, max_depth=3, learning_rate=0.07)
            model.fit(train[feats], train["target"])
            
            pred = model.predict(df[feats].iloc[-1:])[0]
            results[s] = {
                "p": pred, 
                "c": df["Close"].iloc[-1], 
                "s": df["sup"].iloc[-1], 
                "r": df["res"].iloc[-1]
            }
        except: continue

    # æ’é™¤ must_watch å¾Œé¸å–é æœŸå›å ±æœ€é«˜å‰ 5
    pool_results = [s for s in results if s not in must_watch]
    top_5 = sorted(pool_results, key=lambda x: results[x]['p'], reverse=True)[:5]
    
    audit_report = audit_and_save(results, top_5)
    
    # è¼¸å‡ºæ¶ˆæ¯æ§‹å»º
    today = datetime.now().strftime("%Y-%m-%d %H:%M EST")
    msg = f"ğŸ‡ºğŸ‡¸ **ç¾è‚¡ AI é ä¼°å ±å‘Š ({today})**\n"
    msg += "----------------------------------\n"
    msg += "ğŸ† **S&P 300 é é¸å‰ 5 å**\n"
    ranks = ["ğŸ¥‡", "ğŸ¥ˆ", "ğŸ¥‰", "ğŸ“ˆ", "ğŸ“ˆ"]
    for idx, s in enumerate(top_5):
        i = results[s]
        msg += f"{ranks[idx]} **{s}**: `é ä¼° {i['p']:+.2%}`\n"
        msg += f"â”” ç¾åƒ¹: `${i['c']:.2f}` (æ”¯æ’: {i['s']:.1f} / å£“åŠ›: {i['r']:.1f})\n"
        
    msg += "\nğŸ’ **æ ¸å¿ƒç›£æ§æ¸…å–®**\n"
    for s in must_watch:
        if s in results:
            emoji = "ğŸš€" if s in ["TSLA", "SOXL", "NVDA"] else "â­"
            i = results[s]
            msg += f"{emoji} **{s}**: `é ä¼° {i['p']:+.2%}`\n"
            msg += f"â”” ç¾åƒ¹: `${i['c']:.2f}` (æ”¯æ’: {i['s']:.1f} / å£“åŠ›: {i['r']:.1f})\n"
            
    msg += audit_report + "\nğŸ’¡ *è¨»ï¼šé ä¼°å€¼ç‚ºå°æœªä¾† 5 å€‹äº¤æ˜“æ—¥å¾Œçš„èµ°å‹¢åˆ¤æ–·ã€‚*"
    requests.post(WEBHOOK_URL, json={"content": msg})

if __name__ == "__main__":
    run()
